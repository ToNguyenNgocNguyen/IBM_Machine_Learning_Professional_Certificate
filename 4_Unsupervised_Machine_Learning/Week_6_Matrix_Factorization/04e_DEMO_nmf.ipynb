{"cells":[{"attachments":{},"cell_type":"markdown","metadata":{},"source":["<center>\n","    <img src=\"https://cf-courses-data.s3.us.cloud-object-storage.appdomain.cloud/assets/logos/SN_web_lightmode.png\" width=\"200\" alt=\"cognitiveclass.ai logo\">\n","</center>\n"]},{"attachments":{},"cell_type":"markdown","metadata":{"run_control":{"marked":true}},"source":["# Machine Learning Foundation\n","\n","## Course 4, Part e: Non-Negative Matrix Factorization DEMO\n"]},{"attachments":{},"cell_type":"markdown","metadata":{},"source":["This exercise illustrates usage of Non-negative Matrix factorization and covers techniques related to sparse matrices and some basic work with Natural Langauge Processing.  We will use NMF to look at the top words for given topics.\n"]},{"attachments":{},"cell_type":"markdown","metadata":{},"source":["## Data\n"]},{"attachments":{},"cell_type":"markdown","metadata":{},"source":["We'll be using the BBC dataset. These are articles collected from 5 different topics, with the data pre-processed. \n","\n","These data are available in the data folder (or online [here](http://mlg.ucd.ie/files/datasets/bbc.zip?utm_medium=Exinfluencer&utm_source=Exinfluencer&utm_content=000026UJ&utm_term=10006555&utm_id=NA-SkillsNetwork-Channel-SkillsNetworkCoursesIBMML0187ENSkillsNetwork821-2023-01-01)). The data consists of a few files. The steps we'll be following are:\n","\n","* *bbc.terms* is just a list of words \n","* *bbc.docs* is a list of artcles listed by topic.\n","\n","At a high level, we're going to \n","\n","1. Turn the `bbc.mtx` file into a sparse matrix (a [sparse matrix](https://docs.scipy.org/doc/scipy/reference/sparse.html?utm_medium=Exinfluencer&utm_source=Exinfluencer&utm_content=000026UJ&utm_term=10006555&utm_id=NA-SkillsNetwork-Channel-SkillsNetworkCoursesIBMML0187ENSkillsNetwork821-2023-01-01) format can be useful for matrices with many values that are 0, and save space by storing the position and values of non-zero elements).\n","1. Decompose that sparse matrix using NMF.\n","1. Use the resulting components of NMF to analyze the topics that result.\n"]},{"attachments":{},"cell_type":"markdown","metadata":{},"source":["## Data Setup\n"]},{"attachments":{},"cell_type":"markdown","metadata":{},"source":["Note: This lab has been updated to work in skillsnetwork for your convenience.\n"]},{"cell_type":"code","execution_count":1,"metadata":{},"outputs":[],"source":["import urllib"]},{"cell_type":"code","execution_count":2,"metadata":{},"outputs":[],"source":["with urllib.request.urlopen('https://cf-courses-data.s3.us.cloud-object-storage.appdomain.cloud/IBM-ML0187EN-SkillsNetwork/labs/module%203/data/bbc.mtx') as r:\n","    content = r.readlines()[2:]"]},{"attachments":{},"cell_type":"markdown","metadata":{},"source":["## Part 1\n","\n","Here, we will turn this into a list of tuples representing a [sparse matrix](https://docs.scipy.org/doc/scipy/reference/sparse.html?utm_medium=Exinfluencer&utm_source=Exinfluencer&utm_content=000026UJ&utm_term=10006555&utm_id=NA-SkillsNetwork-Channel-SkillsNetworkCoursesIBMML0187ENSkillsNetwork821-2023-01-01). Remember the description of the file from above:\n","\n","* *bbc.mtx* is a list: first column is **wordID**, second is **articleID** and the third is the number of times that word appeared in that article.\n","\n","So, if word 1 appears in article 3, 2 times, one element of our list will be:\n","\n","`(1, 3, 2)`\n"]},{"cell_type":"code","execution_count":3,"metadata":{},"outputs":[{"data":{"text/plain":["[(1, 1, 1),\n"," (1, 7, 2),\n"," (1, 11, 1),\n"," (1, 14, 1),\n"," (1, 15, 2),\n"," (1, 19, 2),\n"," (1, 21, 1),\n"," (1, 29, 1)]"]},"execution_count":3,"metadata":{},"output_type":"execute_result"}],"source":["sparsemat = [tuple(map(int,map(float,c.split()))) for c in content]\n","# Let's examine the first few elements\n","sparsemat[:8]"]},{"attachments":{},"cell_type":"markdown","metadata":{},"source":["## Part 2: Preparing Sparse Matrix data for NMF \n"]},{"attachments":{},"cell_type":"markdown","metadata":{},"source":["We will use the [coo matrix](https://docs.scipy.org/doc/scipy/reference/generated/scipy.sparse.coo_matrix.html?utm_medium=Exinfluencer&utm_source=Exinfluencer&utm_content=000026UJ&utm_term=10006555&utm_id=NA-SkillsNetwork-Channel-SkillsNetworkCoursesIBMML0187ENSkillsNetwork821-2023-01-01) function to turn the sparse matrix into an array. \n"]},{"cell_type":"code","execution_count":4,"metadata":{},"outputs":[{"data":{"text/plain":["(2225, 9635)"]},"execution_count":4,"metadata":{},"output_type":"execute_result"}],"source":["import numpy as np\n","from scipy.sparse import coo_matrix\n","cols = [x[0] - 1 for x in sparsemat]\n","rows = [x[1] - 1  for x in sparsemat]\n","values = [x[2] for x in sparsemat]\n","coo = coo_matrix((values, (rows, cols)))\n","coo.toarray().shape"]},{"attachments":{},"cell_type":"markdown","metadata":{},"source":["## NMF\n"]},{"attachments":{},"cell_type":"markdown","metadata":{},"source":["NMF is a way of decomposing a matrix of documents and words so that one of the matrices can be interpreted as the \"loadings\" or \"weights\" of each word on a topic. \n"]},{"attachments":{},"cell_type":"markdown","metadata":{},"source":["Check out [the NMF documentation](http://scikit-learn.org/stable/modules/generated/sklearn.decomposition.NMF.html?utm_medium=Exinfluencer&utm_source=Exinfluencer&utm_content=000026UJ&utm_term=10006555&utm_id=NA-SkillsNetwork-Channel-SkillsNetworkCoursesIBMML0187ENSkillsNetwork821-2023-01-01) and the [examples of topic extraction using NMF and LDA](http://scikit-learn.org/0.18/auto_examples/applications/topics_extraction_with_nmf_lda.html?utm_medium=Exinfluencer&utm_source=Exinfluencer&utm_content=000026UJ&utm_term=10006555&utm_id=NA-SkillsNetwork-Channel-SkillsNetworkCoursesIBMML0187ENSkillsNetwork821-2023-01-01).\n"]},{"attachments":{},"cell_type":"markdown","metadata":{},"source":["## Part 3\n","\n","Here, we will import `NMF`, define a model object with 5 components, and `fit_transform` the data created above.\n"]},{"cell_type":"code","execution_count":5,"metadata":{},"outputs":[{"data":{"text/plain":["(2225, 5)"]},"execution_count":5,"metadata":{},"output_type":"execute_result"}],"source":["# Surpress warnings from using older version of sklearn:\n","def warn(*args, **kwargs):\n","    pass\n","import warnings\n","warnings.warn = warn\n","\n","from sklearn.decomposition import NMF\n","model = NMF(n_components=5, init='random', random_state=818)\n","doc_topic = model.fit_transform(coo)\n","\n","doc_topic.shape\n","# we should have 9636 observations (articles) and five latent features"]},{"cell_type":"code","execution_count":6,"metadata":{},"outputs":[{"data":{"text/plain":["array([1, 1, 1, ..., 3, 3, 2], dtype=int64)"]},"execution_count":6,"metadata":{},"output_type":"execute_result"}],"source":["# find feature with highest value per doc\n","np.argmax(doc_topic, axis=1)"]},{"attachments":{},"cell_type":"markdown","metadata":{},"source":["## Part 4: \n","\n","Check out the `components` of this model:\n"]},{"cell_type":"code","execution_count":7,"metadata":{},"outputs":[{"data":{"text/plain":["(5, 9635)"]},"execution_count":7,"metadata":{},"output_type":"execute_result"}],"source":["model.components_.shape"]},{"attachments":{},"cell_type":"markdown","metadata":{},"source":["This is five rows, each of which is a \"topic\" containing the weights of each word on that topic. The exercise is to _get a list of the top 10 words for each topic_. We can just store this in a list of lists.\n"]},{"attachments":{},"cell_type":"markdown","metadata":{},"source":["**Note:** Just like we read in the data above, we'll have to read in the words from the `bbc.terms` file.\n"]},{"cell_type":"code","execution_count":8,"metadata":{},"outputs":[],"source":["with urllib.request.urlopen('https://cf-courses-data.s3.us.cloud-object-storage.appdomain.cloud/IBM-ML0187EN-SkillsNetwork/labs/module%203/data/bbc.terms') as r:\n","    content = r.readlines()\n","words = [str(c.strip(), 'utf-8') for c in content]"]},{"cell_type":"code","execution_count":9,"metadata":{},"outputs":[{"data":{"text/html":["<div>\n","<style scoped>\n","    .dataframe tbody tr th:only-of-type {\n","        vertical-align: middle;\n","    }\n","\n","    .dataframe tbody tr th {\n","        vertical-align: top;\n","    }\n","\n","    .dataframe thead th {\n","        text-align: right;\n","    }\n","</style>\n","<table border=\"1\" class=\"dataframe\">\n","  <thead>\n","    <tr style=\"text-align: right;\">\n","      <th></th>\n","      <th>ad</th>\n","      <th>sale</th>\n","      <th>boost</th>\n","      <th>time</th>\n","      <th>warner</th>\n","      <th>profit</th>\n","      <th>quarterli</th>\n","      <th>media</th>\n","      <th>giant</th>\n","      <th>jump</th>\n","      <th>...</th>\n","      <th>£339</th>\n","      <th>denialofservic</th>\n","      <th>ddo</th>\n","      <th>seagrav</th>\n","      <th>bot</th>\n","      <th>wirelessli</th>\n","      <th>streamcast</th>\n","      <th>peripher</th>\n","      <th>headphon</th>\n","      <th>flavour</th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <th>topic_1</th>\n","      <td>1.109794</td>\n","      <td>0.000000</td>\n","      <td>0.147521</td>\n","      <td>1.805085</td>\n","      <td>0.000000</td>\n","      <td>0.000000</td>\n","      <td>0.000000</td>\n","      <td>0.290339</td>\n","      <td>0.000000</td>\n","      <td>0.007622</td>\n","      <td>...</td>\n","      <td>0.000000</td>\n","      <td>0.000189</td>\n","      <td>0.003569</td>\n","      <td>0.005304</td>\n","      <td>0.000000</td>\n","      <td>0.000000</td>\n","      <td>0.000000</td>\n","      <td>0.000000</td>\n","      <td>0.000000</td>\n","      <td>0.000000</td>\n","    </tr>\n","    <tr>\n","      <th>topic_2</th>\n","      <td>0.906610</td>\n","      <td>2.135102</td>\n","      <td>0.555638</td>\n","      <td>1.619654</td>\n","      <td>0.015276</td>\n","      <td>1.232641</td>\n","      <td>0.091248</td>\n","      <td>0.058898</td>\n","      <td>0.346788</td>\n","      <td>0.206330</td>\n","      <td>...</td>\n","      <td>0.001106</td>\n","      <td>0.000000</td>\n","      <td>0.000000</td>\n","      <td>0.000000</td>\n","      <td>0.000000</td>\n","      <td>0.000000</td>\n","      <td>0.002087</td>\n","      <td>0.002166</td>\n","      <td>0.000000</td>\n","      <td>0.001380</td>\n","    </tr>\n","    <tr>\n","      <th>topic_3</th>\n","      <td>0.678384</td>\n","      <td>0.411546</td>\n","      <td>0.050976</td>\n","      <td>4.003071</td>\n","      <td>0.037892</td>\n","      <td>0.000000</td>\n","      <td>0.000000</td>\n","      <td>0.189766</td>\n","      <td>0.084304</td>\n","      <td>0.128306</td>\n","      <td>...</td>\n","      <td>0.000554</td>\n","      <td>0.000000</td>\n","      <td>0.000000</td>\n","      <td>0.000000</td>\n","      <td>0.000000</td>\n","      <td>0.000000</td>\n","      <td>0.000000</td>\n","      <td>0.002014</td>\n","      <td>0.004688</td>\n","      <td>0.000000</td>\n","    </tr>\n","    <tr>\n","      <th>topic_4</th>\n","      <td>0.696425</td>\n","      <td>0.415502</td>\n","      <td>0.054580</td>\n","      <td>1.219848</td>\n","      <td>0.051868</td>\n","      <td>0.051111</td>\n","      <td>0.008216</td>\n","      <td>1.221179</td>\n","      <td>0.279640</td>\n","      <td>0.000000</td>\n","      <td>...</td>\n","      <td>0.025132</td>\n","      <td>0.019692</td>\n","      <td>0.061144</td>\n","      <td>0.074941</td>\n","      <td>0.136037</td>\n","      <td>0.020642</td>\n","      <td>0.039628</td>\n","      <td>0.029288</td>\n","      <td>0.027964</td>\n","      <td>0.020455</td>\n","    </tr>\n","    <tr>\n","      <th>topic_5</th>\n","      <td>0.475060</td>\n","      <td>0.372709</td>\n","      <td>0.123657</td>\n","      <td>0.986447</td>\n","      <td>0.021659</td>\n","      <td>0.041599</td>\n","      <td>0.000000</td>\n","      <td>0.051945</td>\n","      <td>0.020607</td>\n","      <td>0.251904</td>\n","      <td>...</td>\n","      <td>0.000000</td>\n","      <td>0.000000</td>\n","      <td>0.000000</td>\n","      <td>0.000000</td>\n","      <td>0.000000</td>\n","      <td>0.000000</td>\n","      <td>0.004888</td>\n","      <td>0.000000</td>\n","      <td>0.000000</td>\n","      <td>0.000000</td>\n","    </tr>\n","  </tbody>\n","</table>\n","<p>5 rows × 9635 columns</p>\n","</div>"],"text/plain":["               ad      sale     boost      time    warner    profit  \\\n","topic_1  1.109794  0.000000  0.147521  1.805085  0.000000  0.000000   \n","topic_2  0.906610  2.135102  0.555638  1.619654  0.015276  1.232641   \n","topic_3  0.678384  0.411546  0.050976  4.003071  0.037892  0.000000   \n","topic_4  0.696425  0.415502  0.054580  1.219848  0.051868  0.051111   \n","topic_5  0.475060  0.372709  0.123657  0.986447  0.021659  0.041599   \n","\n","         quarterli     media     giant      jump  ...      £339  \\\n","topic_1   0.000000  0.290339  0.000000  0.007622  ...  0.000000   \n","topic_2   0.091248  0.058898  0.346788  0.206330  ...  0.001106   \n","topic_3   0.000000  0.189766  0.084304  0.128306  ...  0.000554   \n","topic_4   0.008216  1.221179  0.279640  0.000000  ...  0.025132   \n","topic_5   0.000000  0.051945  0.020607  0.251904  ...  0.000000   \n","\n","         denialofservic       ddo   seagrav       bot  wirelessli  streamcast  \\\n","topic_1        0.000189  0.003569  0.005304  0.000000    0.000000    0.000000   \n","topic_2        0.000000  0.000000  0.000000  0.000000    0.000000    0.002087   \n","topic_3        0.000000  0.000000  0.000000  0.000000    0.000000    0.000000   \n","topic_4        0.019692  0.061144  0.074941  0.136037    0.020642    0.039628   \n","topic_5        0.000000  0.000000  0.000000  0.000000    0.000000    0.004888   \n","\n","         peripher  headphon   flavour  \n","topic_1  0.000000  0.000000  0.000000  \n","topic_2  0.002166  0.000000  0.001380  \n","topic_3  0.002014  0.004688  0.000000  \n","topic_4  0.029288  0.027964  0.020455  \n","topic_5  0.000000  0.000000  0.000000  \n","\n","[5 rows x 9635 columns]"]},"execution_count":9,"metadata":{},"output_type":"execute_result"}],"source":["import pandas as pd\n","topic_words = pd.DataFrame(model.components_, columns=words, index=['topic_'+str(i + 1) for i in range(5)])\n","topic_words"]},{"attachments":{},"cell_type":"markdown","metadata":{},"source":["The original data had 5 topics, as listed in `bbc.docs` (which these topic words relate to). \n","\n","```\n","Business\n","Entertainment\n","Politics\n","Sport\n","Tech\n","```\n","\n","In \"real life\", we would have found a way to use these to inform the model. But for this little demo, we can just compare the recovered topics to the original ones. And they seem to match reasonably well. The order is different, which is to be expected in this kind of model.\n"]},{"cell_type":"code","execution_count":10,"metadata":{},"outputs":[{"data":{"text/plain":["2225"]},"execution_count":10,"metadata":{},"output_type":"execute_result"}],"source":["with urllib.request.urlopen('https://cf-courses-data.s3.us.cloud-object-storage.appdomain.cloud/IBM-ML0187EN-SkillsNetwork/labs/module%203/data/bbc.docs') as r:\n","    doc_content = r.readlines()\n","    \n","len(doc_content)"]},{"cell_type":"code","execution_count":11,"metadata":{},"outputs":[{"data":{"text/html":["<div>\n","<style scoped>\n","    .dataframe tbody tr th:only-of-type {\n","        vertical-align: middle;\n","    }\n","\n","    .dataframe tbody tr th {\n","        vertical-align: top;\n","    }\n","\n","    .dataframe thead th {\n","        text-align: right;\n","    }\n","</style>\n","<table border=\"1\" class=\"dataframe\">\n","  <thead>\n","    <tr style=\"text-align: right;\">\n","      <th></th>\n","      <th>topic_1</th>\n","      <th>topic_2</th>\n","      <th>topic_3</th>\n","      <th>topic_4</th>\n","      <th>topic_5</th>\n","    </tr>\n","    <tr>\n","      <th>index</th>\n","      <th></th>\n","      <th></th>\n","      <th></th>\n","      <th></th>\n","      <th></th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <th>business</th>\n","      <td>0.023584</td>\n","      <td>0.251565</td>\n","      <td>0.007547</td>\n","      <td>0.024401</td>\n","      <td>0.006144</td>\n","    </tr>\n","    <tr>\n","      <th>entertainment</th>\n","      <td>0.020826</td>\n","      <td>0.057755</td>\n","      <td>0.036762</td>\n","      <td>0.039328</td>\n","      <td>0.154993</td>\n","    </tr>\n","    <tr>\n","      <th>politics</th>\n","      <td>0.261662</td>\n","      <td>0.078559</td>\n","      <td>0.014332</td>\n","      <td>0.025091</td>\n","      <td>0.009294</td>\n","    </tr>\n","    <tr>\n","      <th>sport</th>\n","      <td>0.026781</td>\n","      <td>0.045077</td>\n","      <td>0.167854</td>\n","      <td>0.005876</td>\n","      <td>0.025784</td>\n","    </tr>\n","    <tr>\n","      <th>tech</th>\n","      <td>0.023849</td>\n","      <td>0.057403</td>\n","      <td>0.115039</td>\n","      <td>0.327589</td>\n","      <td>0.020415</td>\n","    </tr>\n","  </tbody>\n","</table>\n","</div>"],"text/plain":["                topic_1   topic_2   topic_3   topic_4   topic_5\n","index                                                          \n","business       0.023584  0.251565  0.007547  0.024401  0.006144\n","entertainment  0.020826  0.057755  0.036762  0.039328  0.154993\n","politics       0.261662  0.078559  0.014332  0.025091  0.009294\n","sport          0.026781  0.045077  0.167854  0.005876  0.025784\n","tech           0.023849  0.057403  0.115039  0.327589  0.020415"]},"execution_count":11,"metadata":{},"output_type":"execute_result"}],"source":["topic_doc = pd.DataFrame(doc_topic, index=[str(i, 'utf-8').split('.')[0] for i in doc_content], columns=['topic_'+str(i+1) for i in range(5)])\n","topic_doc.reset_index().groupby('index').mean()"]},{"cell_type":"code","execution_count":12,"metadata":{},"outputs":[{"data":{"text/html":["<div>\n","<style scoped>\n","    .dataframe tbody tr th:only-of-type {\n","        vertical-align: middle;\n","    }\n","\n","    .dataframe tbody tr th {\n","        vertical-align: top;\n","    }\n","\n","    .dataframe thead th {\n","        text-align: right;\n","    }\n","</style>\n","<table border=\"1\" class=\"dataframe\">\n","  <thead>\n","    <tr style=\"text-align: right;\">\n","      <th></th>\n","      <th>Topics</th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <th>topic_1</th>\n","      <td>politics</td>\n","    </tr>\n","    <tr>\n","      <th>topic_2</th>\n","      <td>business</td>\n","    </tr>\n","    <tr>\n","      <th>topic_3</th>\n","      <td>sport</td>\n","    </tr>\n","    <tr>\n","      <th>topic_4</th>\n","      <td>tech</td>\n","    </tr>\n","    <tr>\n","      <th>topic_5</th>\n","      <td>entertainment</td>\n","    </tr>\n","  </tbody>\n","</table>\n","</div>"],"text/plain":["                Topics\n","topic_1       politics\n","topic_2       business\n","topic_3          sport\n","topic_4           tech\n","topic_5  entertainment"]},"execution_count":12,"metadata":{},"output_type":"execute_result"}],"source":["mapping = topic_doc.reset_index().groupby('index').mean().idxmax().to_frame().rename(columns={0:'Topics'})\n","mapping"]},{"cell_type":"code","execution_count":13,"metadata":{},"outputs":[],"source":["result = pd.concat([mapping, topic_words], join='inner', axis=1)\n","result.set_index('Topics', inplace=True)"]},{"cell_type":"code","execution_count":14,"metadata":{},"outputs":[{"data":{"text/html":["<div>\n","<style scoped>\n","    .dataframe tbody tr th:only-of-type {\n","        vertical-align: middle;\n","    }\n","\n","    .dataframe tbody tr th {\n","        vertical-align: top;\n","    }\n","\n","    .dataframe thead th {\n","        text-align: right;\n","    }\n","</style>\n","<table border=\"1\" class=\"dataframe\">\n","  <thead>\n","    <tr style=\"text-align: right;\">\n","      <th></th>\n","      <th>parti</th>\n","      <th>labour</th>\n","      <th>govern</th>\n","      <th>elect</th>\n","      <th>blair</th>\n","      <th>peopl</th>\n","      <th>tori</th>\n","      <th>minist</th>\n","      <th>plan</th>\n","      <th>brown</th>\n","      <th>...</th>\n","      <th>branson</th>\n","      <th>slew</th>\n","      <th>cowboi</th>\n","      <th>bright</th>\n","      <th>£26m</th>\n","      <th>zheng</th>\n","      <th>120m</th>\n","      <th>lt</th>\n","      <th>costeffect</th>\n","      <th>flavour</th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <th>politics</th>\n","      <td>7.272066</td>\n","      <td>6.859606</td>\n","      <td>6.4028</td>\n","      <td>5.984097</td>\n","      <td>5.031092</td>\n","      <td>4.831863</td>\n","      <td>4.167926</td>\n","      <td>4.078225</td>\n","      <td>3.491092</td>\n","      <td>3.330722</td>\n","      <td>...</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","    </tr>\n","  </tbody>\n","</table>\n","<p>1 rows × 9635 columns</p>\n","</div>"],"text/plain":["             parti    labour  govern     elect     blair     peopl      tori  \\\n","politics  7.272066  6.859606  6.4028  5.984097  5.031092  4.831863  4.167926   \n","\n","            minist      plan     brown  ...  branson  slew  cowboi  bright  \\\n","politics  4.078225  3.491092  3.330722  ...      0.0   0.0     0.0     0.0   \n","\n","          £26m  zheng  120m   lt  costeffect  flavour  \n","politics   0.0    0.0   0.0  0.0         0.0      0.0  \n","\n","[1 rows x 9635 columns]"]},"metadata":{},"output_type":"display_data"},{"data":{"text/html":["<div>\n","<style scoped>\n","    .dataframe tbody tr th:only-of-type {\n","        vertical-align: middle;\n","    }\n","\n","    .dataframe tbody tr th {\n","        vertical-align: top;\n","    }\n","\n","    .dataframe thead th {\n","        text-align: right;\n","    }\n","</style>\n","<table border=\"1\" class=\"dataframe\">\n","  <thead>\n","    <tr style=\"text-align: right;\">\n","      <th></th>\n","      <th>year</th>\n","      <th>increas</th>\n","      <th>wage</th>\n","      <th>compani</th>\n","      <th>busi</th>\n","      <th>minimum</th>\n","      <th>govern</th>\n","      <th>rate</th>\n","      <th>market</th>\n","      <th>economi</th>\n","      <th>...</th>\n","      <th>insan</th>\n","      <th>flak</th>\n","      <th>vega</th>\n","      <th>rene</th>\n","      <th>gp</th>\n","      <th>pager</th>\n","      <th>xrai</th>\n","      <th>pander</th>\n","      <th>28th</th>\n","      <th>bang</th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <th>business</th>\n","      <td>6.709741</td>\n","      <td>4.237554</td>\n","      <td>3.782039</td>\n","      <td>3.15333</td>\n","      <td>2.94221</td>\n","      <td>2.915635</td>\n","      <td>2.868437</td>\n","      <td>2.629689</td>\n","      <td>2.598373</td>\n","      <td>2.466916</td>\n","      <td>...</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","    </tr>\n","  </tbody>\n","</table>\n","<p>1 rows × 9635 columns</p>\n","</div>"],"text/plain":["              year   increas      wage  compani     busi   minimum    govern  \\\n","business  6.709741  4.237554  3.782039  3.15333  2.94221  2.915635  2.868437   \n","\n","              rate    market   economi  ...  insan  flak  vega  rene   gp  \\\n","business  2.629689  2.598373  2.466916  ...    0.0   0.0   0.0   0.0  0.0   \n","\n","          pager  xrai  pander  28th  bang  \n","business    0.0   0.0     0.0   0.0   0.0  \n","\n","[1 rows x 9635 columns]"]},"metadata":{},"output_type":"display_data"},{"data":{"text/html":["<div>\n","<style scoped>\n","    .dataframe tbody tr th:only-of-type {\n","        vertical-align: middle;\n","    }\n","\n","    .dataframe tbody tr th {\n","        vertical-align: top;\n","    }\n","\n","    .dataframe thead th {\n","        text-align: right;\n","    }\n","</style>\n","<table border=\"1\" class=\"dataframe\">\n","  <thead>\n","    <tr style=\"text-align: right;\">\n","      <th></th>\n","      <th>game</th>\n","      <th>plai</th>\n","      <th>time</th>\n","      <th>player</th>\n","      <th>world</th>\n","      <th>first</th>\n","      <th>win</th>\n","      <th>get</th>\n","      <th>go</th>\n","      <th>on</th>\n","      <th>...</th>\n","      <th>bt</th>\n","      <th>vendor</th>\n","      <th>257</th>\n","      <th>desktop</th>\n","      <th>ibm</th>\n","      <th>stiffen</th>\n","      <th>lenovo</th>\n","      <th>surplus</th>\n","      <th>restraint</th>\n","      <th>flavour</th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <th>sport</th>\n","      <td>15.865935</td>\n","      <td>6.752707</td>\n","      <td>4.003071</td>\n","      <td>2.932378</td>\n","      <td>2.871058</td>\n","      <td>2.740374</td>\n","      <td>2.613089</td>\n","      <td>2.533307</td>\n","      <td>2.487597</td>\n","      <td>2.371216</td>\n","      <td>...</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","    </tr>\n","  </tbody>\n","</table>\n","<p>1 rows × 9635 columns</p>\n","</div>"],"text/plain":["            game      plai      time    player     world     first       win  \\\n","sport  15.865935  6.752707  4.003071  2.932378  2.871058  2.740374  2.613089   \n","\n","            get        go        on  ...   bt  vendor  257  desktop  ibm  \\\n","sport  2.533307  2.487597  2.371216  ...  0.0     0.0  0.0      0.0  0.0   \n","\n","       stiffen  lenovo  surplus  restraint  flavour  \n","sport      0.0     0.0      0.0        0.0      0.0  \n","\n","[1 rows x 9635 columns]"]},"metadata":{},"output_type":"display_data"},{"data":{"text/html":["<div>\n","<style scoped>\n","    .dataframe tbody tr th:only-of-type {\n","        vertical-align: middle;\n","    }\n","\n","    .dataframe tbody tr th {\n","        vertical-align: top;\n","    }\n","\n","    .dataframe thead th {\n","        text-align: right;\n","    }\n","</style>\n","<table border=\"1\" class=\"dataframe\">\n","  <thead>\n","    <tr style=\"text-align: right;\">\n","      <th></th>\n","      <th>peopl</th>\n","      <th>mobil</th>\n","      <th>phone</th>\n","      <th>technolog</th>\n","      <th>servic</th>\n","      <th>music</th>\n","      <th>digit</th>\n","      <th>user</th>\n","      <th>network</th>\n","      <th>on</th>\n","      <th>...</th>\n","      <th>madam</th>\n","      <th>lahor</th>\n","      <th>auf</th>\n","      <th>strauss</th>\n","      <th>jeanpierr</th>\n","      <th>acclaim</th>\n","      <th>turin</th>\n","      <th>philharmon</th>\n","      <th>jule</th>\n","      <th>hinder</th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <th>tech</th>\n","      <td>6.515048</td>\n","      <td>6.114551</td>\n","      <td>5.233037</td>\n","      <td>4.633311</td>\n","      <td>3.961518</td>\n","      <td>3.57757</td>\n","      <td>2.946419</td>\n","      <td>2.818726</td>\n","      <td>2.634326</td>\n","      <td>2.546418</td>\n","      <td>...</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","    </tr>\n","  </tbody>\n","</table>\n","<p>1 rows × 9635 columns</p>\n","</div>"],"text/plain":["         peopl     mobil     phone  technolog    servic    music     digit  \\\n","tech  6.515048  6.114551  5.233037   4.633311  3.961518  3.57757  2.946419   \n","\n","          user   network        on  ...  madam  lahor  auf  strauss  \\\n","tech  2.818726  2.634326  2.546418  ...    0.0    0.0  0.0      0.0   \n","\n","      jeanpierr  acclaim  turin  philharmon  jule  hinder  \n","tech        0.0      0.0    0.0         0.0   0.0     0.0  \n","\n","[1 rows x 9635 columns]"]},"metadata":{},"output_type":"display_data"},{"data":{"text/html":["<div>\n","<style scoped>\n","    .dataframe tbody tr th:only-of-type {\n","        vertical-align: middle;\n","    }\n","\n","    .dataframe tbody tr th {\n","        vertical-align: top;\n","    }\n","\n","    .dataframe thead th {\n","        text-align: right;\n","    }\n","</style>\n","<table border=\"1\" class=\"dataframe\">\n","  <thead>\n","    <tr style=\"text-align: right;\">\n","      <th></th>\n","      <th>best</th>\n","      <th>song</th>\n","      <th>music</th>\n","      <th>year</th>\n","      <th>award</th>\n","      <th>film</th>\n","      <th>25</th>\n","      <th>angel</th>\n","      <th>robbi</th>\n","      <th>british</th>\n","      <th>...</th>\n","      <th>limp</th>\n","      <th>scan</th>\n","      <th>builtin</th>\n","      <th>text</th>\n","      <th>tablet</th>\n","      <th>dock</th>\n","      <th>laptop</th>\n","      <th>antiviru</th>\n","      <th>firewal</th>\n","      <th>flavour</th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <th>entertainment</th>\n","      <td>11.895329</td>\n","      <td>9.829428</td>\n","      <td>9.578887</td>\n","      <td>6.745143</td>\n","      <td>6.661391</td>\n","      <td>4.356695</td>\n","      <td>4.104535</td>\n","      <td>3.95287</td>\n","      <td>3.34941</td>\n","      <td>3.209357</td>\n","      <td>...</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","    </tr>\n","  </tbody>\n","</table>\n","<p>1 rows × 9635 columns</p>\n","</div>"],"text/plain":["                    best      song     music      year     award      film  \\\n","entertainment  11.895329  9.829428  9.578887  6.745143  6.661391  4.356695   \n","\n","                     25    angel    robbi   british  ...  limp  scan  builtin  \\\n","entertainment  4.104535  3.95287  3.34941  3.209357  ...   0.0   0.0      0.0   \n","\n","               text  tablet  dock  laptop  antiviru  firewal  flavour  \n","entertainment   0.0     0.0   0.0     0.0       0.0      0.0      0.0  \n","\n","[1 rows x 9635 columns]"]},"metadata":{},"output_type":"display_data"}],"source":["for i, topic in enumerate(result.index):\n","    display(result.sort_values(by=topic, axis=1, ascending=False).iloc[i, :].to_frame().T)"]},{"attachments":{},"cell_type":"markdown","metadata":{},"source":["---\n","### Machine Learning Foundation (C) 2020 IBM Corporation\n"]}],"metadata":{"kernelspec":{"display_name":"MyPythonEnv","language":"python","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.9.15"}},"nbformat":4,"nbformat_minor":4}
